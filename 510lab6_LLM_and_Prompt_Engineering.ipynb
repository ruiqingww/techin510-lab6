{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kIIUoMvr8xPI",
        "fH-L9Sukeh5L"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruiqingww/techin510-lab6/blob/main/510lab6_LLM_and_Prompt_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agenda\n",
        "\n",
        "- What is Large Language Model?\n",
        "- How does Large Language Models work?\n",
        "- What are the use cases of LLMs?\n",
        "- How to use LLMs effectively? (Prompt Engineering)\n",
        "- How to make LLms smarter?\n",
        "    - Give me more information (RAG)\n",
        "    - Train it more (fine-tuning)"
      ],
      "metadata": {
        "id": "ZPSPXFT-tRME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is Large Language Model?"
      ],
      "metadata": {
        "id": "ZHoQ67sgug2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The core task of the language model is next word prediction. Given a sequence of input words, the neural network predicts the probability distribution of what the next word will be.\n",
        "\n",
        "- Think of it like iPhone keyboard autocomplete\n",
        "\n",
        "- Web data (10TB) -> Training on 6k GPUs for 12 days (~$2M) -> ~140GB file\n",
        "\n",
        "- Compressing the Internet into a small file (~100x smaller)"
      ],
      "metadata": {
        "id": "zSaunicZwKot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How do Large Language Models work?"
      ],
      "metadata": {
        "id": "9Z0Eb7sAwBMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A large neural network with billions of parameters (knobs)\n",
        "- We can measure the output, and turn the knobs to optimize performance.\n",
        "- We don't fully understand how the knobs work (blockbox)\n",
        "- Give it a prompt, and it will \"dream\" the rest of the texts"
      ],
      "metadata": {
        "id": "I4CvtjDcwO9e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What are the use cases of LLMs?"
      ],
      "metadata": {
        "id": "NMa68vC00yGf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- NLP tasks\n",
        "    - Text generation\n",
        "    - Classification\n",
        "    - Summarization\n",
        "    - Name-Entity-Recognition\n",
        "    - Question-Answering\n",
        "    - Translation\n",
        "- Higher level tasks\n",
        "    - Research\n",
        "    - Assistants"
      ],
      "metadata": {
        "id": "iZdON5la01kj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why and why not LLMs"
      ],
      "metadata": {
        "id": "F7ukX_-U3JAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advantages and Disadvantages"
      ],
      "metadata": {
        "id": "o1HgJRMm3L8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Advantages\n",
        "\n",
        "- Versatility\n",
        "- Ability to learn new tasks\n",
        "- Large knowledge\n",
        "- Strong performance\n",
        "\n",
        "### Disadvantages\n",
        "\n",
        "- Lack of true understanding\n",
        "- Hallucination and inconsistency\n",
        "- Bias and fairness issues\n",
        "- Lack of grounding\n",
        "- Difficulty with reasoning\n",
        "- Opaque decision-making\n",
        "- Computational cost\n",
        "- Privacy and security"
      ],
      "metadata": {
        "id": "0RsyCNgc4D6P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## When to use and not to use LLMs"
      ],
      "metadata": {
        "id": "ZD6VFLgI4IVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### When to use LLMs\n",
        "\n",
        "- Creative writing\n",
        "- NLP tasks\n",
        "    - Classification\n",
        "    - Summarization\n",
        "    - Name-Entity-Recognition\n",
        "    - Question-Answering\n",
        "    - Translation\n",
        "\n",
        "### When not to use LLMs\n",
        "\n",
        "- Math\n",
        "- Logic reasoning\n",
        "- Ground truth critical tasks"
      ],
      "metadata": {
        "id": "fADQwz0w4yzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to use LLMs effectively? (Prompt Engineering)\n",
        "\n",
        "Try all of the following prompting techniques using `OpenAI` or `Gemini` API"
      ],
      "metadata": {
        "id": "4bYSvgYP5MKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY = getpass.getpass()\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "kGnLcWyTFo9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88c75692-4805-4dc2-92c7-512bb39ab30c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-pro')"
      ],
      "metadata": {
        "id": "HtLbXTfQJJ4R"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_content(prompt):\n",
        "    response = model.generate_content(prompt)\n",
        "    print(response.text)"
      ],
      "metadata": {
        "id": "KVE86s9PJPc-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Six strategies for getting better results\n",
        "\n",
        "- Write clear instructions\n",
        "- Provide reference text\n",
        "- Split complex tasks into simpler subtasks\n",
        "- Give the model time to \"think\"\n",
        "- Use external tools\n",
        "- Test changes systematically\n",
        "\n",
        "source: [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering/strategy-write-clear-instructions)"
      ],
      "metadata": {
        "id": "hDGHQNqa6ZW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write clear instructions"
      ],
      "metadata": {
        "id": "-8ZZsDbP60FG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# More detailed prompts\n",
        "prompt1 = \"Tell me a music description\"\n",
        "\n",
        "prompt2 = \"Tell me a music description for running. Please write it in a professional language.\"\n",
        "\n",
        "gen_content(prompt1)\n",
        "print('---------------')\n",
        "gen_content(prompt2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "YfjFYH2tJ2Zn",
        "outputId": "7768aeef-9f22-4e23-87ee-c0d882572a9b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the realm of sonic artistry, where melodies dance and rhythms intertwine, emerges a symphony that captivates the soul. The music unfolds like a tapestry woven with intricate threads of sound, each note a vibrant hue in a kaleidoscope of auditory delight.\n",
            "\n",
            "The strings soar with a mournful elegance, their tremolo creating a shimmer akin to shimmering stars against the velvet canvas of the night sky. The piano weaves its way through the composition, its ivory keys dancing under nimble fingers, adding a touch of melancholy grace.\n",
            "\n",
            "Drums thunder like the heartbeat of the earth, driving the rhythm with a primal power that sets the body in motion. The bass provides a steady foundation, its low, rumbling tones grounding the music in a deep and resonant embrace.\n",
            "\n",
            "Guitars shimmer with ethereal beauty, their strings plucked with precision and passion, creating an atmosphere that is both ethereal and evocative. The vocals soar above the instrumentation, a voice that carries the weight of emotion, pouring out a torrent of raw and unfiltered feeling.\n",
            "\n",
            "The lyrics, penned with poetic brilliance, paint vivid pictures in the mind's eye, evoking a range of sensations that span the spectrum of human experience. Themes of love, loss, hope, and despair intertwine, creating a narrative that resonates with the listener's own journey.\n",
            "\n",
            "The music builds to a crescendo, reaching a peak of intensity that leaves the body trembling and the soul soaring. Then, as if fading into a distant dream, it gradually subsides, leaving behind a lingering echo that lingers long after the final note has faded away.\n",
            "\n",
            "Like a masterpiece from the Louvre, this music transcends its own medium, becoming an experience that captivates the senses, stirs the emotions, and leaves an enduring mark on the heart.\n",
            "---------------\n",
            "A high-energy, driving electronic rhythm forms the foundation, gradually building intensity as layered synths and rhythmic percussive elements create a sense of urgency. A catchy melodic hook weaves through the arrangement, providing motivation and a compelling auditory cue for sustained effort. The music is structured with periodic crescendos and releases, mirroring the ebb and flow of the runner's stride and providing a motivating sonic landscape that enhances focus and endurance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask the model to adope a persona\n",
        "\n",
        "prompt = \"You are an expert at music generation for running. Please take the user's request and give a music description for the latter music generation.\"\n",
        "gen_content(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "bi6GTG6OKPHu",
        "outputId": "50876ee7-c58b-4337-8dc9-83a22bb27b05"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Music Description:**\n",
            "\n",
            "This music is designed to accompany you on your running journey, providing an energetic and motivating soundtrack that fuels your steps. The beats are strong and steady, propelling you forward with a sense of purpose. The melodies are soaring and uplifting, inspiring you to push your limits and embrace the challenge.\n",
            "\n",
            "The instrumentation is a blend of electronic elements and organic instruments, creating a dynamic and immersive soundscape. Driving rhythms lay the foundation, while ethereal synths and soaring strings add a touch of grandeur. The occasional vocal samples provide encouragement and motivation, reminding you that you're not alone in this endeavor.\n",
            "\n",
            "The tempo is carefully crafted to maintain a consistent pace, while the intervals of higher intensity sections provide bursts of energy to help you overcome fatigue. The overall sound is designed to create an auditory experience that complements your physical exertion, making your run feel less like a chore and more like an exhilarating adventure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use delimiters to clearly indicate the distinct parts of the input\n",
        "\n",
        "prompt = \"\"\"You are an expert in technical recruiting. Please read the following resume and job description. Give me suggestion on how to improve my resume\n",
        "\n",
        "<job description>\n",
        "Amazon\n",
        "Senior software engineering\n",
        "The candidate should.....\n",
        "\n",
        "</job description>\n",
        "<resume>\n",
        "Ian Chen\n",
        "Software Engineer\n",
        "</resume>\n",
        "\"\"\"\n",
        "gen_content(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "bWJki2J5KgeL",
        "outputId": "12e03663-9417-4d04-9c06-b4afea759f03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Suggestions to Improve the Resume for the Senior Software Engineering Role at Amazon:**\n",
            "\n",
            "* **Highlight Relevant Experience and Skills:**\n",
            "   - Quantify accomplishments using specific metrics to demonstrate impact and results achieved.\n",
            "   - Showcase projects or roles that demonstrate experience in areas mentioned in the job description, such as cloud computing, software development, and data structures.\n",
            "* **Emphasize Amazon-Specific Keywords:**\n",
            "   - Use keywords from the job description throughout the resume, such as \"Senior Software Engineer,\" \"Amazon,\" \"cloud computing,\" and \"data structures.\" This will help recruiters quickly identify your relevant skills and experience.\n",
            "* **Include a Tailored Cover Letter:**\n",
            "   - Write a specific cover letter that addresses the key requirements of the position and explains how your skills and experience align with Amazon's needs.\n",
            "* **Use a Professional Resume Format:**\n",
            "   - Ensure the resume is well-organized, easy to read, and uses a professional font and formatting style.\n",
            "* **Expand the Summary Section:**\n",
            "   - Include a brief summary that highlights your key qualifications, years of experience, and any relevant certifications or licenses.\n",
            "* **Proofread Carefully:**\n",
            "   - Double-check for any spelling, grammar, or formatting errors before submitting your resume.\n",
            "\n",
            "**Additional Suggestions:**\n",
            "\n",
            "* **Consider Using a Resume Builder:** Many online resume builders offer templates and tools to help you create a professional-looking resume.\n",
            "* **Network with Recruiters:** Attend industry events or connect with recruiters on LinkedIn to get your resume noticed.\n",
            "* **Practice Your Interview Skills:** Prepare for technical and behavioral interview questions to increase your chances of success.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Include details in your query to get more relevant answers\n",
        "\n",
        "```\n",
        "Summarize the meeting notes.\n",
        "```\n",
        "\n",
        "```\n",
        "Summarize the meeting notes in a single paragraph. Then write a markdown list of the speakers and each of their key points. Finally, list the next steps or action items suggested by the speakers, if any.\n",
        "```\n",
        "\n",
        "#### Ask the model to adopt a persona\n",
        "\n",
        "```\n",
        "You are an expert in Python programming. You have 20 years of programming experience.\n",
        "```\n",
        "\n",
        "#### Use delimiters to clearly indicate distinct parts of the input\n",
        "\n",
        "```\n",
        "Summarize the text delimited by triple quotes with a haiku.\n",
        "\n",
        "\"\"\"insert text here\"\"\"\n",
        "```\n",
        "\n",
        "```\n",
        "You will be provided with a pair of articles (delimited with XML tags) about the same topic. First summarize the arguments of each article. Then indicate which of them makes a better argument and explain why.\n",
        "\n",
        "<article> insert first article here </article>\n",
        "\n",
        "<article> insert second article here </article>\n",
        "```\n",
        "\n",
        "```\n",
        "You will be provided with a thesis abstract and a suggested title for it. The thesis title should give the reader a good idea of the topic of the thesis but should also be eye-catching. If the title does not meet these criteria, suggest 5 alternatives.\n",
        "\n",
        "Abstract: insert abstract here\n",
        "\n",
        "Title: insert title here\n",
        "```\n",
        "\n",
        "#### Specify the steps required to complete a task\n",
        "Some tasks are best specified as a sequence of steps. Writing the steps out explicitly can make it easier for the model to follow them.\n",
        "\n",
        "```\n",
        "Use the following step-by-step instructions to respond to user inputs.\n",
        "\n",
        "Step 1 - The user will provide you with text in triple quotes. Summarize this text in one sentence with a prefix that says \"Summary: \".\n",
        "\n",
        "Step 2 - Translate the summary from Step 1 into Spanish, with a prefix that says \"Translation: \".\n",
        "\n",
        "\"\"\"insert text here\"\"\"\n",
        "```"
      ],
      "metadata": {
        "id": "jx8mUfWYeAyR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EUXai9MwFnP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Provide Reference Text\n",
        "\n"
      ],
      "metadata": {
        "id": "kIIUoMvr8xPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Use the provided articles delimited by triple quotes to answer questions. If the answer cannot be found in the articles, write \"I could not find an answer.\"\n",
        "\n",
        "<insert articles, each delimited by triple quotes>\n",
        "\n",
        "Question: <insert question here>\n",
        "```\n",
        "\n",
        "#### Answer with citations from a reference text\n",
        "\n",
        "If the input has been supplemented with relevant knowledge, it's straightforward to request that the model add citations to its answers by referencing passages from provided documents. Note that citations in the output can then be verified programmatically by string matching within the provided documents.\n",
        "\n",
        "```\n",
        "You will be provided with a document delimited by triple quotes and a question. Your task is to answer the question using only the provided document and to cite the passage(s) of the document used to answer the question. If the document does not contain the information needed to answer this question then simply write: \"Insufficient information.\" If an answer to the question is provided, it must be annotated with a citation. Use the following format for to cite relevant passages ({\"citation\": …}).\n",
        "\n",
        "\"\"\"<insert document here>\"\"\"\n",
        "\n",
        "Question: <insert question here>\n",
        "```"
      ],
      "metadata": {
        "id": "e7iX2DvQedCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split complex tasks into simpler subtasks"
      ],
      "metadata": {
        "id": "fH-L9Sukeh5L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Multi-step prompting\n",
        "\n",
        "1. Write a prompt to ask the model to classify the users input\n",
        "1. Based on the ansewr from the model, choose a second prompt to complete the task\n",
        "\n",
        "Example: Customer service chatbot\n",
        "\n",
        "```\n",
        "You are a complaint categorizer. Based on the users input and the following criteria, please output the category of the users inquery.\n",
        "```\n",
        "\n",
        "A: troubleshooting\n",
        "\n",
        "```\n",
        "You are a customer service agent. Please provide helpful instruction to help the user troubleshoot the product.\n",
        "```"
      ],
      "metadata": {
        "id": "eMp_60TTeuAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Summarization\n",
        "\n",
        "**Summarize conversations that's too long**\n",
        "\n",
        "LLMs have limited context window lengths. For long conversations that requires context preservation, consider summarize the previous conversation and start new conversation. (GPT-4 16k or 32k)\n",
        "\n",
        "**Chunk long texts then summarize recursively**\n",
        "\n",
        "Chunk longs texts (a book) into reasonably sized tokens (1024, 2048, 4906 tokens, experiemnt with them) then summarize recusively to produce summary of summaries.\n",
        "\n",
        "You can consider running (refine) strategy for summarization"
      ],
      "metadata": {
        "id": "CMi_c4l3fqhE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Give model time to think"
      ],
      "metadata": {
        "id": "iBXxrDzzhGMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Read the following JD and resume, do the following tasks\n",
        "1. Output \"good fit\" or \"not good fit\"\n",
        "2. Give the strengh and weaknesses of the candidate for this job\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "Read the following JD and resume, do the following tasks\n",
        "1. Give the strengh and weaknesses of the candidate for this job\n",
        "2. Output \"good fit\" or \"not good fit\"\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dNtIiQP1AbHq",
        "outputId": "c9ff7f59-0620-4bca-90de-d30ddf632b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nRead the following JD and resume, do the following tasks\\n1. Give the strengh and weaknesses of the candidate for this job\\n2. Output \"good fit\" or \"not good fit\"\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chain of thought**\n",
        "\n",
        "The order of output matters.\n",
        "\n",
        "Ask the model to think and layout the strategy first before outputting the final decision.\n",
        "\n",
        "**Inner monologue to hide chain of thoughts**\n",
        "\n",
        "Ask the model to output the intermediate thoughts in a structured format (such as \"\"\" triple quotes) that's easy to parsed in a post procesisng step.\n",
        "\n",
        "**multi step prompting**\n",
        "\n",
        "In a evaluation or reasoning task\n",
        "\n",
        "- Ask the model to perform task on it's own\n",
        "- Evaluate the users input\n",
        "- (Bonus) Ask a different persona to give final verdict"
      ],
      "metadata": {
        "id": "CSK-_Xj2hIaL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### User External Tools"
      ],
      "metadata": {
        "id": "L07wK_6-iMZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Search for relevent information and inject into context**\n",
        "\n",
        "- Vector searching using embeddings\n",
        "- Google search\n",
        "\n",
        "**Ask model to generate code**\n",
        "\n",
        "```\n",
        "You can write and execute Python code by enclosing it in triple backticks, e.g. ```code goes here```. Use this to perform calculations.\n",
        "\n",
        "Find all real-valued roots of the following polynomial: 3*x**5 - 5*x**4 - 3*x**3 - 7*x - 10.\n",
        "```\n",
        "\n",
        "```\n",
        "You can write and execute Python code by enclosing it in triple backticks. Also note that you have access to the following module to help users send messages to their friends:\n",
        "\n",
        "```python\n",
        "import message\n",
        "message.write(to=\"John\", message=\"Hey, want to meetup after work?\")```\n",
        "```\n",
        "\n",
        "It's dangerous to run model generated code without sandboxing.\n",
        "\n",
        "Consider using [function calling](https://platform.openai.com/docs/guides/function-calling) instead"
      ],
      "metadata": {
        "id": "Xf9n2ZeiiOwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "def get_weather(location_name):\n",
        "    weather = requests.get(location_name)\n",
        "    return weather\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "You have access to this function, here is the function definition\n",
        "\n",
        "{\n",
        "    \"function_name\": \"get_weather\",\n",
        "    \"arguments: [\n",
        "        \"location_name\": \"this is the name of the location to search for the weather\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "Questions: What is the weather in Seattle?\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "get_weather(\"Seattle\")\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ShI_lWD3DINW",
        "outputId": "186bbb16-48ea-4752-e8c0-186105abb2b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nget_weather(\"Seattle\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "## Documents\n",
        "\n",
        "- [Steven Wolfram's intro to LLM](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)\n",
        "- [Mistral AI docs](https://docs.mistral.ai/guides/resources/)\n",
        "- [OpenAI Prompt Engineering](https://platform.openai.com/examples)\n",
        "- [Elastic's intro to LLM](https://www.elastic.co/what-is/large-language-models)\n",
        "\n",
        "## Youtube\n",
        "\n",
        "- [Awesome talk by Andrej Karpathy](https://youtu.be/zjkBMFhNj_g?si=wPxLgMJ2D-CZsQvv)\n",
        "- [Large Language Models](https://www.youtube.com/watch?v=YDiSFS-yHwk)\n",
        "\n",
        "## Colab Notebooks\n",
        "\n",
        "- https://colab.research.google.com/drive/1uQABWrbU17DwLQdDZ8k5d_UJVlrAkwZ5?usp=sharing\n",
        "\n",
        "## GitHub\n",
        "\n",
        "- https://github.com/mlabonne/llm-course\n",
        "\n",
        "- https://github.com/datainsightat/introduction_llm\n",
        "\n",
        "- https://github.com/Ryota-Kawamura/Generative-AI-with-LLMs/tree/main\n",
        "\n",
        "- https://github.com/sinanuozdemir/oreilly-hands-on-transformers\n",
        "\n",
        "- https://github.com/gkamradt/langchain-tutorials\n",
        "\n",
        "- https://github.com/openai/openai-cookbook\n",
        "\n",
        "- https://github.com/dair-ai/Prompt-Engineering-Guide\n",
        "\n",
        "- https://github.com/ksm26/chatGPT-Prompt-Engineering-for-Developers\n",
        "\n",
        "- https://github.com/kevinamiri/Instructgpt-prompts\n",
        "\n",
        "- https://github.com/promptslab/Promptify\n",
        "\n",
        "- https://github.com/dair-ai/Prompt-Engineering-Guide\n",
        "\n",
        "## Papers\n",
        "\n",
        "- [Attention is all you need](https://arxiv.org/abs/1706.03762)\n",
        "- [FINETUNED LANGUAGE MODELS ARE ZERO-SHOT LEARNERS](https://openreview.net/pdf?id=gEZrGCozdqR)\n",
        "- [Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165)"
      ],
      "metadata": {
        "id": "RA64OmGW6LEL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eHpT2dBBj0Zl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}